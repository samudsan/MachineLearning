{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #Pandas is a library written for the Python programming language for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series, which is a Panel Data. Therefore, the library is named is Pandas. Pandas library is built on NumPy package\n",
    "import matplotlib.pyplot as plt  # Matplotlib is a plotting library for the Python programming language and its numerical mathematics extension NumPy. It provides an object-oriented API for embedding plots into applications using general-purpose GUI toolkits like Tkinter, wxPython, Qt, or GTK+.\n",
    "import numpy as np #NumPy is a package in Python used for Scientific Computing. NumPy package is used to perform different operations. The ndarray (NumPy Array) is a multidimensional array used to store values of same datatype. These arrays are indexed just like Sequences, starts with zero.\n",
    "import seaborn as sns # Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading .csv DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading MNIST data set from git hub\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/samudsan/MachineLearning/master/Data%20Sets/Mnist/train.csv\")\n",
    "#classesLabel = df[\"label\"]\n",
    "df = df.drop(\"label\", axis = 1)\n",
    "\n",
    "# Slicing dataset(taking part of data set)\n",
    "subdf = df.head(1000)\n",
    "label = subdf.drop(\"label\", axis = 1) #removing class column from df and adding in a separete variable\n",
    "\n",
    "print(subdf.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading .sqlite3 DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                                                138706\n",
       "Id                                                                   150524\n",
       "ProductId                                                        0006641040\n",
       "UserId                                                        ACITT7DI6IDDL\n",
       "ProfileName                                                 shari zychinski\n",
       "HelpfulnessNumerator                                                      0\n",
       "HelpfulnessDenominator                                                    0\n",
       "Score                                                              positive\n",
       "Time                                                              939340800\n",
       "Summary                                           EVERY book is educational\n",
       "Text                      this witty little book makes my son laugh at l...\n",
       "CleanedText               witti littl book make son laugh loud recit car...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "con = sqlite3.connect(r'/home/sandeep/Desktop/San/finalss.sqlite') \n",
    "filtered_data = pd.read_sql_query(\"\"\"SELECT * FROM Reviewwss WHERE Score != 3 LIMIT 5000\"\"\", con) \n",
    "filtered_data.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving python objects Using Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                                                138706\n",
       "Id                                                                   150524\n",
       "ProductId                                                        0006641040\n",
       "UserId                                                        ACITT7DI6IDDL\n",
       "ProfileName                                                 shari zychinski\n",
       "HelpfulnessNumerator                                                      0\n",
       "HelpfulnessDenominator                                                    0\n",
       "Score                                                              positive\n",
       "Time                                                              939340800\n",
       "Summary                                           EVERY book is educational\n",
       "Text                      this witty little book makes my son laugh at l...\n",
       "CleanedText               witti littl book make son laugh loud recit car...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# here I am trying to save the filtered_data. once it has run, it will save a file in local machine\n",
    "# we can load that pickle file later.\n",
    "\n",
    "with open(\"data_pickle\", \"wb\") as f: # define the file name and encoding with binary\n",
    "    pickle.dump(filtered_data, f) # saving filter\n",
    "\n",
    "with open(\"data_pickle\", \"rb\") as f: # reading the same file with same encoding\n",
    "    loaded_using_pickle = pickle.load(f)\n",
    "    \n",
    "loaded_using_pickle.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving python objects Using Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandeep/anaconda3/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "index                                                                138706\n",
       "Id                                                                   150524\n",
       "ProductId                                                        0006641040\n",
       "UserId                                                        ACITT7DI6IDDL\n",
       "ProfileName                                                 shari zychinski\n",
       "HelpfulnessNumerator                                                      0\n",
       "HelpfulnessDenominator                                                    0\n",
       "Score                                                              positive\n",
       "Time                                                              939340800\n",
       "Summary                                           EVERY book is educational\n",
       "Text                      this witty little book makes my son laugh at l...\n",
       "CleanedText               witti littl book make son laugh loud recit car...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joblib is more efficient on objects that carry large numpy arras inernally \n",
    "# as is often the case for fitted scikit-learn estimators\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(filtered_data, \"data_joblib\")\n",
    "\n",
    "loaded_using_joblib = joblib.load(\"data_joblib\")\n",
    "loaded_using_joblib.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas DataFrame\n",
    "\n",
    "`DataFrame.iat`\n",
    "Fast integer location scalar accessor.\n",
    "\n",
    "`DataFrame.loc`\n",
    "Purely label-location based indexer for selection by label.\n",
    "\n",
    "`Series.iloc`\n",
    "Purely integer-location based indexing for selection by position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label.iloc[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"age\", \"year\", \"nodes\", \"status\"]\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/samudsan/MachineLearning/master/Data%20Sets/Haberman/haberman.csv\", names = columns)\n",
    "\n",
    "df.head()  # to know top 5 observations\n",
    "df[\"status\"].value_counts() # tells us count of each observation in status\n",
    "df.shape # To know number of of rows(datapoints) and columns(features)\n",
    "df[\"status\"].size #to know the number observations in feature status\n",
    "df[\"age\"].values[20] # prints the 20th obesrvation with respect to age.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identifiers:**\n",
    "\n",
    "    \\d = any number\n",
    "    \\D = anything but a number\n",
    "    \\s = space\n",
    "    \\S = anything but a space\n",
    "    \\w = any letter\n",
    "    \\W = anything but a letter\n",
    "    . = any character, except for a new line\n",
    "    \\b = space around whole words\n",
    "    \\. = period. must use backslash, because . normally means any character.\n",
    "    \n",
    "Legend\n",
    "\n",
    "    structure\n",
    "    ( ) grouping\n",
    "    a|b either a or b\n",
    "    quantifier\n",
    "    ? 0 or 1 occurrence\n",
    "    * 0 or any number of occurrences\n",
    "    + any number of occurrences\n",
    "    {x} x occurrences\n",
    "    {x,y} x to y occurrences\n",
    "    \n",
    "positions\n",
    "\n",
    "    ` ^ / $ line beginning / ending `\n",
    "    \\b word border position\n",
    "    \\B in-word position\n",
    "    (?=x) lookahead if x comes next\n",
    "    \n",
    "characters\n",
    "\n",
    "    . any character\n",
    "    \\d / \\D digit / any other\n",
    "    \\s / \\S whitespace / any other\n",
    "    \\w / \\W alpha-numeric / any other\n",
    "    [ab] any character a or b\n",
    "    [^ab] any character but a and b\n",
    "\n",
    "\n",
    "**Modifiers:**\n",
    "\n",
    "    {1,3} = for digits, u expect 1-3 counts of digits, or \"places\"\n",
    "    + = match 1 or more\n",
    "    ? = match 0 or 1 repetitions.\n",
    "    * = match 0 or MORE repetitions\n",
    "    $ = matches at the end of string\n",
    "    ^ = matches start of a string\n",
    "    | = matches either/or. Example x|y = will match either x or y\n",
    "    [] = range, or \"variance\"\n",
    "    {x} = expect to see this amount of the preceding code.\n",
    "    {x,y} = expect to see this x-y amounts of the precedng code\n",
    "\n",
    "**White Space Charts**\n",
    "\n",
    "    \\n = new line\n",
    "    \\s = space\n",
    "    \\t = tab\n",
    "    \\e = escape\n",
    "    \\f = form feed\n",
    "    \\r = carriage return\n",
    "    Characters to REMEMBER TO ESCAPE IF USED!\n",
    "\n",
    "    . + * ? [ ] $ ^ ( ) { } | \\\n",
    "\n",
    "**Brackets:**\n",
    "\n",
    "[] = quant[ia]tative = will find either quantitative, or quantatative.\n",
    "[a-z] = return any lowercase letter a-z\n",
    "[1-5a-qA-Z] = return all numbers 1-5, lowercase letters a-q and uppercase A-Z\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps in Text processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic feature extraction using text data**\n",
    "    \n",
    "    Number of words\n",
    "    Number of characters\n",
    "    Average word length\n",
    "    Number of stopwords\n",
    "    Number of special characters\n",
    "    Number of numerics\n",
    "    Number of uppercase words\n",
    "**Basic Text Pre-processing of text data**\n",
    "    \n",
    "    Lower casing\n",
    "    Punctuation removal\n",
    "    Stopwords removal\n",
    "    Frequent words removal\n",
    "    Rare words removal\n",
    "    Spelling correction\n",
    "    Tokenization\n",
    "    Stemming\n",
    "    Lemmatization\n",
    "**Advance Text Processing**\n",
    "    \n",
    "    N-grams\n",
    "    Term Frequency\n",
    "    Inverse Document Frequency\n",
    "    Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "    Bag of Words\n",
    "    Sentiment Analysis\n",
    "    Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Simlarity Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7444497 ]\n",
      " [0.        ]\n",
      " [0.59714687]\n",
      " [0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "train_set = [\"president of India\",\"machine learning is awesome\", \"python of president is awesome\", \"thanks for reading\"]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix_train = tfidf_vectorizer.fit_transform(train_set)\n",
    "tfidf_matrix_test = tfidf_vectorizer.transform([\"president of \"])\n",
    "\n",
    "print(cosine_similarity(tfidf_matrix_train,tfidf_matrix_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
